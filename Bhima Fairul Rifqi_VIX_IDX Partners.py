# -*- coding: utf-8 -*-
"""PBI: ID/X - Data Scientist

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jy7ao3hJp0IBixr_3uz-4k-3zvpIkrfe

# Data n Library Setup
"""

import pandas as pd
import numpy as np
import statistics as stats
import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as st
import math
import warnings
import sklearn
warnings.filterwarnings('ignore')
from datetime import datetime as dt
import regex as re

# Plot Setup

from matplotlib import rcParams
rcParams['figure.figsize'] = (20, 10)
rcParams['axes.spines.right'] = True
rcParams['axes.spines.top'] = True
rcParams['axes.spines.bottom'] = True
rcParams['lines.linewidth'] = 2.5
rcParams['xtick.labelsize'] = 'x-large'
rcParams['ytick.labelsize'] = 'x-large'

# Table Display Setup: Show All Columns

pd.set_option('display.max_columns', None)

"""## Dataset"""

# Data Import
raw_df = pd.read_csv('/content/drive/MyDrive/Kerja/Laboratory/PBI: ID X - Data Scientist/loan_data_2007_2014.csv')

# Data Preview
raw_df.head()

# About The Data
raw_df.info()

"""# EDA"""

# Data for use
df = raw_df.copy()

"""## Features Grouping

To group features by its contexts.
"""

# Features with high percetages of null value
high_null_features = []

for col in df.columns:
  if df[col].isnull().sum() > 0.5 * len(df):
    high_null_features.append(col)

# Features with only 1 value
constant_features = []

for col in df.columns:
  if df[col].nunique() == 1:
    constant_features.append(col)

# Other groups
free_text_features = ['url', 'desc', 'title']
identifier_features = ['id', 'member_id']
irrelevent_features = ['Unnamed: 0', 'zip_code', 'addr_state', 'purpose', 'grade', 'emp_title']
time_features = ['issue_d', 'earliest_cr_line', 'last_pymnt_d', 'last_credit_pull_d']
over_imbalance_features = ['pymnt_plan']
future_features = ['recoveries', 'next_pymnt_d', 'collection_recovery_fee', 'total_rec_late_fee', 'tot_coll_amt']

to_drop = high_null_features + constant_features + free_text_features + identifier_features + irrelevent_features + time_features + over_imbalance_features + future_features

# Categoric Features
cat_features = []

for col in df.columns:
  if df[col].dtype == 'object' and col not in to_drop:
    cat_features.append(col)

# Numerical Features
num_features = []

for col in df.columns:
  if col not in to_drop + cat_features:
    num_features.append(col)

"""to_drop contains the features that won't be included in the modelling

## Features Engineering
"""

# Extracting the number in sub_grade
import regex as re

df['grade_number'] = df['sub_grade'].apply(lambda x: re.findall(r'\d', x)[0])

# Aggregating the time-type data
for col in time_features:
  df[col] = pd.to_datetime(df[col].astype(str), format='%b-%y', errors='coerce')

df['last_credit_pull_d'] = pd.to_datetime(df['last_credit_pull_d'].astype(str), format='%b-%y', errors='coerce')

today_year = df['last_credit_pull_d'].max().year
first_credit_year = df['earliest_cr_line'].dt.year

df.loc[df['earliest_cr_line'].dt.year > df['last_credit_pull_d'].dt.year, 'earliest_cr_line'] -= pd.DateOffset(years=100)
df['first_credit_to_issue_gap'] = ((df['issue_d'] - df['earliest_cr_line']).dt.days / 365).clip(lower=0)

# Simplification: term
df['long_term'] = df['term'].apply(lambda x: 1 if x == ' 60 months' else 0)
df['initial_listing_whole'] = df['initial_list_status'].apply(lambda x: 1 if x == 'w' else 0)

# Simplification: verification_status
df['income_source_verification'] = df['verification_status'].apply(lambda x: 0 if x == 'Not Verified' else 1)

# Assign the target feature
green_status = ['Current', 'Fully Paid', 'In Grace Period', 'Does not meet the credit policy. Status:Fully Paid']

df['in_risk'] = df['loan_status'].apply(lambda x: 1 if x not in green_status else 0)

engineered_features = ['grade_number', 'verification_status', 'loan_status', 'term', 'initial_list_status']

"""To avoid multicolinearity, engineered features (engineered_features) will be dropped.

## Univariate Analysis
"""

# Check the status
df['in_risk'].value_counts()

# Demography: Clients' Working Experience
sns.countplot(y='emp_length', data=df)
plt.show()

"""Found out that majority of the clients been working for more than 10yrs."""

# Monitoring Loan Status
sns.countplot(y='loan_status', data=df)
plt.show()

# Number of Loan by its term
sns.countplot(x='term', data=df)
fig = plt.gcf()
fig.set_size_inches(5, 5)
plt.title('Loan Term')
# no spines
plt.gca().spines['top'].set_visible(False)
plt.gca().spines['right'].set_visible(False)
# plt.gca().spines['bottom'].set_visible(False)
plt.gca().spines['left'].set_visible(False)
plt.yticks([])
plt.ylabel('')
# annotations
for p in plt.gca().patches:
  plt.gca().annotate(
    f'{int(p.get_height())}',
    (p.get_x() + p.get_width() / 2, p.get_height()),
    ha='center', va='bottom',
    xytext=(0, 5), textcoords='offset points'
  )
plt.tight_layout()
plt.show()

# Outlier checking
fig, ax = plt.subplots(figsize=(10, 5))
sns.boxplot(x=df['annual_inc'])
plt.title('Annual Income')
plt.xticks(visible=False)
plt.tight_layout()

"""## Multivariate Analysis

### Correlation Heatmap
"""

# Correlation
corr = df[num_features].corr()

sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.show()

# High Correlated Features
high_corr_features = []
upper = df[num_features].corr().abs().where(np.triu(np.ones(df[num_features].corr().shape), k=1).astype(bool))
for col in upper.columns:
	for row in upper.index:
		if upper.loc[row, col] > 0.5:
			high_corr_features.append(col)
high_corr_features = list(set(high_corr_features))
high_corr_features

"""To avoid multicollinearity, high_corr_features will be dropped from the modelling.

### Insight Findings
"""

import plotly.express as px

fig = px.sunburst(df, path=['grade', 'purpose'])
fig.show()

# countplot
# sns.countplot(data=df, x='AgeGroup', hue='Response')
ct = pd.crosstab(df['grade'], df['in_risk'])
ct_perc = ct.div(ct.sum(axis=1), axis=0) * 100

fig, ax = plt.subplots(figsize=(15,10))
lefts = [0] * len(ct)
colors = ['#4CAF50', '#F44336']

for i, col in enumerate(ct.columns):
	bars = ax.barh(ct.index, ct_perc[col], left=lefts, color=colors[i], label=col)
	for j, (v, c, left) in enumerate(zip(ct_perc[col], ct[col], lefts)):
		if v > 0:
			ax.text(left + v/2, j, f'{c}\n({v:.1f}%)', ha='center', va='center', color='white', fontsize=13)
	lefts = [lefts[k] + ct_perc[col][k] for k in range(len(lefts))]

ax.set_title('Risk Status by Loan Grades', fontsize=32)
ax.legend(title='Clicked', loc='upper right')
plt.xticks(visible=False)
plt.xlabel('')
# no spine
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
# ax.spines['left'].set_visible(False)
ax.xaxis.set_ticks([])
ax.xaxis.set_ticklabels([])
plt.tight_layout()
plt.show()

# Statistical test: int_rate with in_risk
import statsmodels.api as sm

x_stat = df[['int_rate']]
x_stat = sm.add_constant(x_stat)
y_stat = df['in_risk']

model = sm.Logit(y_stat, x_stat)
result = model.fit()

print(result.summary())

"""Hypothesis:
H0: Interest rate doesn't affect the risk significantly.
H1: Interest rate affect the risk significantly.
Decision making rules: reject H0 if p-value < 0.05.

Results: p-value nears 0
Conclusion: Interest rate affect the risk significantly.
"""

df.groupby('grade')['loan_amnt'].describe()

df.groupby('grade')['int_rate'].describe()

# Interest rate for each flag status

df_red = df[df['in_risk'] == 1]
df_green = df[df['in_risk'] == 0]

plt.figure(figsize=(7,3))

sns.kdeplot(df_red['int_rate'], label='In Risk', color='red')
sns.kdeplot(df_green['int_rate'], label='No Risk', color='green')

plt.title('Density Distribution of Interest Rate for Each Risk Status')
plt.legend()
plt.yticks(visible=False)
plt.ylabel('')
# no spine
plt.gca().spines['top'].set_visible(False)
plt.gca().spines['right'].set_visible(False)
plt.gca().spines['left'].set_visible(False)
plt.yticks([])
plt.tight_layout()
plt.show()

# Difference test of interest rate
green_int = df_green['int_rate']
red_int = df_red['int_rate']

green_int = green_int.dropna()
red_int = red_int.dropna()

from scipy.stats import ttest_ind

stat, p = ttest_ind(green_int, red_int)
print('Statistics=%.3f, p=%.3f' % (stat, p))

"""Hypothesis:
H0: Interest rates are same.
H1: Interest rates aren't same.
Decision making rules: reject H0 if p-value < 0.05.

Results: p-value nears 0
Conclusion: Interest rate aren't same.
"""

df.groupby('grade')['annual_inc'].describe()

# Difference test of annual income
green_inc = df_green['annual_inc']
red_inc = df_red['annual_inc']

green_inc = green_inc.dropna()
red_inc = red_inc.dropna()

from scipy.stats import ttest_ind

stat, p = ttest_ind(green_inc, red_inc)
print('Statistics=%.3f, p=%.3f' % (stat, p))

"""Hypothesis:
H0: Annual incomes are same.
H1: Annual incomes aren't same.
Decision making rules: reject H0 if p-value < 0.05.

Results: p-value nears 0
Conclusion: Annual incomes aren't same.

## Complete DF
"""

complete_df = df.copy()

"""# Feature Selection"""

# Features Selection
to_drop = to_drop + high_corr_features + engineered_features

df.drop(columns=to_drop, inplace=True)

# Assign x and y
y = df['in_risk']
x = df.drop(columns=['in_risk'])

"""## Final Features Grouping"""

# Assign new groups of features
new_cat_features = ['income_source_verification', 'long_term', 'initial_listing_whole']
final_cat_features = []

for i in cat_features:
  if i in x.columns:
    final_cat_features.append(i)

for i in new_cat_features:
  final_cat_features.append(i)

final_num_features = []

for i in x.columns:
  if i not in final_cat_features:
    final_num_features.append(i)

# Assign binary features for easier encode
binary_features = []

for col in final_cat_features:
  if x[col].nunique() == 2:
    binary_features.append(col)

final_features = list(x.columns)

"""# Data Splitting"""

# Split the data for modelling
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
x_train.shape, x_test.shape, y_train.shape, y_test.shape

"""# Data Preprocessing

## Missing Values
"""

from sklearn.impute import SimpleImputer

cat_imputer = SimpleImputer(strategy='most_frequent')
num_imputer = SimpleImputer(strategy='median')

x_train[final_cat_features] = cat_imputer.fit_transform(x_train[final_cat_features])
x_train[final_num_features] = num_imputer.fit_transform(x_train[final_num_features])

x_test[final_cat_features] = cat_imputer.transform(x_test[final_cat_features])
x_test[final_num_features] = num_imputer.transform(x_test[final_num_features])

"""## Duplicates"""

x_train.duplicated().sum()

"""## Encode"""

x_train[final_cat_features]

letters = list(sorted(complete_df['grade'].unique()))
sub_grade_map = {}
sub_grade_value = 1
for l in letters:
	for n in range(1,6):
		sub_grade_map[f'{l}{n}'] = sub_grade_value
		sub_grade_value += 1
sub_grade_map

# emp_lengt
emp_length_map = {
  '< 1 year': 0,
  '1 year': 1,
  '2 years': 2,
  '3 years': 3,
  '4 years': 4,
  '5 years': 5,
  '6 years': 6,
  '7 years': 7,
  '8 years': 8,
  '9 years': 9,
  '10+ years': 10
}

# home_ownersip
home_ownership_map = {
  'NONE': 0,
  'RENT': 1,
  'OTHER': 2,
  'ANY': 2,
  'MORTGAGE': 3,
  'OWN': 4
}

# Encoding
xs = [x_train, x_test]
maps = {
    'sub_grade': sub_grade_map,
    'emp_length': emp_length_map,
    'home_ownership': home_ownership_map
}

for df in xs:
	for col, mp in maps.items():
		df[col] = df[col].map(mp)

"""## Feature Scaling"""

from sklearn.preprocessing import RobustScaler, MinMaxScaler

r_scaler = RobustScaler() # For numeric features
mm_scaler = MinMaxScaler() # For encoded (ordinal) categoric features

x_train[final_cat_features] = mm_scaler.fit_transform(x_train[final_cat_features])
x_test[final_cat_features] = mm_scaler.transform(x_test[final_cat_features])

x_train[final_num_features] = r_scaler.fit_transform(x_train[final_num_features])
x_test[final_num_features] = r_scaler.transform(x_test[final_num_features])

"""## Label Balancing"""

# Label Balancing
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
x_train, y_train = smote.fit_resample(x_train, y_train)

"""# Model Development & Evaluation"""

# Evaluation Metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import classification_report, confusion_matrix

"""## Logistic Regression"""

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(x_train, y_train)
y_test_pred = lr.predict(x_test)

accuracy = accuracy_score(y_test, y_test_pred)
precision = precision_score(y_test, y_test_pred)
recall = recall_score(y_test, y_test_pred)
f1 = f1_score(y_test, y_test_pred)
roc_auc = roc_auc_score(y_test, y_test_pred)

print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')
print(f'ROC AUC: {roc_auc}')

print(classification_report(y_test, y_test_pred))

cm = confusion_matrix(y_test, y_test_pred)
cm_df = pd.DataFrame(cm, columns=['Predicted: 0', 'Predicted: 1'], index=['Actual: 0', 'Actual: 1'])
cm_df

"""## Decision Tree"""

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()
dt.fit(x_train, y_train)
y_test_pred = dt.predict(x_test)

accuracy = accuracy_score(y_test, y_test_pred)
precision = precision_score(y_test, y_test_pred)
recall = recall_score(y_test, y_test_pred)
f1 = f1_score(y_test, y_test_pred)
roc_auc = roc_auc_score(y_test, y_test_pred)

print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')
print(f'ROC AUC: {roc_auc}')

print(classification_report(y_test, y_test_pred))

cm = confusion_matrix(y_test, y_test_pred)
cm_df = pd.DataFrame(cm, columns=['Predicted: 0', 'Predicted: 1'], index=['Actual: 0', 'Actual: 1'])
cm_df

"""## Random Forest"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()
rf.fit(x_train, y_train)
y_test_pred = rf.predict(x_test)

accuracy = accuracy_score(y_test, y_test_pred)
precision = precision_score(y_test, y_test_pred)
recall = recall_score(y_test, y_test_pred)
f1 = f1_score(y_test, y_test_pred)
roc_auc = roc_auc_score(y_test, y_test_pred)

print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')
print(f'ROC AUC: {roc_auc}')

print(classification_report(y_test, y_test_pred))

cm = confusion_matrix(y_test, y_test_pred)
cm_df = pd.DataFrame(cm, columns=['Predicted: 0', 'Predicted: 1'], index=['Actual: 0', 'Actual: 1'])
cm_df

"""## XGBoost"""

from xgboost import XGBClassifier

xgb = XGBClassifier()
xgb.fit(x_train, y_train)
y_test_pred = xgb.predict(x_test)

accuracy = accuracy_score(y_test, y_test_pred)
precision = precision_score(y_test, y_test_pred)
recall = recall_score(y_test, y_test_pred)
f1 = f1_score(y_test, y_test_pred)
roc_auc = roc_auc_score(y_test, y_test_pred)

print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')
print(f'ROC AUC: {roc_auc}')

print(classification_report(y_test, y_test_pred))

cm = confusion_matrix(y_test, y_test_pred)
cm_df = pd.DataFrame(cm, columns=['Predicted: 0', 'Predicted: 1'], index=['Actual: 0', 'Actual: 1'])
cm_df

"""## MLP"""

from sklearn.neural_network import MLPClassifier

mlp = MLPClassifier()
mlp.fit(x_train, y_train)
y_test_pred = mlp.predict(x_test)

accuracy = accuracy_score(y_test, y_test_pred)
precision = precision_score(y_test, y_test_pred)
recall = recall_score(y_test, y_test_pred)
f1 = f1_score(y_test, y_test_pred)
roc_auc = roc_auc_score(y_test, y_test_pred)

print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')
print(f'ROC AUC: {roc_auc}')

print(classification_report(y_test, y_test_pred))

cm = confusion_matrix(y_test, y_test_pred)
cm_df = pd.DataFrame(cm, columns=['Predicted: 0', 'Predicted: 1'], index=['Actual: 0', 'Actual: 1'])
cm_df

"""# Model Interpretation"""

# Feature importance analysis
from xgboost import plot_importance

plot_importance(xgb, importance_type='gain', max_num_features=len(final_features))
plt.grid(False)
plt.ylabel('')
plt.title('XGBoost Feature Importance', fontsize = 32)
# no spines
plt.gca().spines['top'].set_visible(False)
plt.gca().spines['right'].set_visible(False)
plt.gca().spines['bottom'].set_visible(False)
plt.xticks([])
plt.tight_layout()
plt.show()

# Feature importance data
xgb_importances = xgb.get_booster().get_score(importance_type='gain')

feature_importances = pd.DataFrame({
    'feature': list(xgb_importances.keys()),
    'importance': list(xgb_importances.values()),
}).sort_values('importance', ascending=False)

feature_importances['weight'] = feature_importances['importance'] / feature_importances['importance'].sum()
feature_importances

# Model export
import joblib

joblib.dump(xgb, 'xgb_model.pkl')